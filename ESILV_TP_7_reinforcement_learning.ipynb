{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage par renforcement\n",
    "\n",
    "    On crée un environnement composé d'une grille, sur laquelle un agent peut se déplacer avec quatre actions :\n",
    "    - \"droite\" ,\"gauche\" ,\"bas\"    ,\"haut\"\n",
    "    - cet environnement récompense de -500 points lorsqu'on sort de la grille, -50 points lorsqu'on entre dans un piège, et + 1000 points quand on atteint le but.\n",
    "    \n",
    "    Il s'agit pour un agent de déterminer une police pour atteindre le but de l'environnement en utilisant les 4 actions. Se notebook a pour vocation à montrer toute la logique de l'apprentissage par renforcement : \n",
    "    - la notion de Reward\n",
    "    - la notion d'étape : je suis dans une position, je fais une action, quel est mon gain ? où est-ce que je me trouve ensuite ?\n",
    "    - la création d'épisodes\n",
    "    - la notion de q_function\n",
    "    - la mise à jour de la q_function \n",
    "    - la création d'une policy de déplacement\n",
    "\n",
    "Aperçu de l'environnement de jeu : \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Classe environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class environnement:\n",
    "    \"\"\"\n",
    "    Cette classe propose les actions possibles, les buts et les gains / pertes selon les positions.\n",
    "    \"\"\"\n",
    "    actions = [\"droite\" ,\"gauche\" ,\"bas\"    ,\"haut\"]\n",
    "    \n",
    "    x_min, x_max = 0, 10 \n",
    "    y_min, y_max = 0, 10\n",
    "\n",
    "    but     = [(7,8) , (3,4)]\n",
    "    pieges  = [(2,3), (3,3), (4,3),\n",
    "               (2,4),\n",
    "               (2,5),(3,5),(4,5),\n",
    "               (6,8), (7,7), (8,7), \n",
    "               (6,7), \n",
    "               (6,9), (7,9), (8,9)]\n",
    "\n",
    "    def get_next_position(self, current_x,current_y, action :str)->(int,int,bool):\n",
    "        \"\"\"\n",
    "        Retourne les nouveaux x,y et si l'agent est sorti de la grille\n",
    "        \"\"\"\n",
    "        # action = \"haut\" / \"bas\" ...\n",
    "        if action in [\"droite\" ]     : move_y  = +1\n",
    "        if action in [\"gauche\" ]     : move_y  = -1\n",
    "        if action in [\"haut\", \"bas\"] : move_y  =  0\n",
    "            \n",
    "        if action in [\"haut\" ]            : move_x  = +1\n",
    "        if action in [\"bas\" ]             : move_x  = -1\n",
    "        if action in [\"droite\", \"gauche\"] : move_x  =  0    \n",
    "            \n",
    "        next_x          = current_x + move_x\n",
    "        next_y          = current_y + move_y\n",
    "        outsider        = False\n",
    "        if next_x < environnement.x_min           : next_x = environnement.x_min   ; outsider = True\n",
    "        if next_y < environnement.y_min           : next_y = environnement.y_min   ; outsider = True\n",
    "        if          environnement.x_max <= next_x : next_x = environnement.x_max-1 ; outsider = True\n",
    "        if          environnement.y_max <= next_y : next_y = environnement.y_max-1 ; outsider = True\n",
    "        return next_x, next_y, outsider\n",
    "    \n",
    "    def get_reward(self, x, y, outsider):\n",
    "        if outsider                      : return -500\n",
    "        if (x,y) in environnement.pieges : return -50\n",
    "        if (x,y) in environnement.but    : return 100000\n",
    "        \n",
    "        return 1\n",
    "        \n",
    "    def est_fini(self, x,y):\n",
    "        return (x,y) in environnement.but\n",
    "    \n",
    "    def get_etape(self, current_x, current_y, action):\n",
    "        \"\"\"\n",
    "        Retourne la nouvelle position, le reward et la potentielle déclaration de fin d'épisode.\n",
    "        \"\"\"\n",
    "        next_x, next_y, outsider = self.get_next_position(current_x, current_y, action)\n",
    "        reward                   = self.get_reward(next_x, next_y, outsider)\n",
    "        est_fini                 = True if outsider else self.est_fini(next_x, next_y)\n",
    "        return (next_x, next_y, reward, est_fini)\n",
    "    \n",
    "    def create_episode(self, agent, max_iter = 200)->list:\n",
    "        \"\"\"\n",
    "        Retourne une liste de conséquences de décisions selon un emplacement.\n",
    "        \"\"\"\n",
    "        episode  = []\n",
    "        fini     = False\n",
    "        while not fini and max_iter>0:\n",
    "            current_x, current_y         = agent.current_x, agent.current_y\n",
    "            action                       = agent.get_action()\n",
    "            next_x, next_y, reward, fini = self.get_etape(current_x, current_y, action)\n",
    "            \n",
    "            episode.append({  \"current_x\"   : current_x, \n",
    "                              \"current_y\"   : current_y, \n",
    "                              \"action\"      : action, \n",
    "                              \"reward\"      : reward, \n",
    "                              \"fini\"        : fini })\n",
    "            \n",
    "            agent.current_x = next_x\n",
    "            agent.current_y = next_y\n",
    "            max_iter -=1\n",
    "            \n",
    "        return episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) classe agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent:\n",
    "    def __init__(self):\n",
    "        self.q_function = {(x,y):{ action : 0 \n",
    "                                      for action in environnement.actions } for x in range(environnement.x_max)  \\\n",
    "                                                                            for y in range(environnement.y_max)  }\n",
    "        self.reset_position()\n",
    "        \n",
    "        \n",
    "    def reset_position(self):\n",
    "        \"\"\"\n",
    "        Retourne au point de départ\n",
    "        \"\"\"\n",
    "        import random\n",
    "        self.current_x = 0\n",
    "        self.current_y = 0\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"\n",
    "        Retourne une action aléatoirement choisie\n",
    "        \"\"\"\n",
    "        import random\n",
    "        return random.choice(environnement.actions)\n",
    "    \n",
    "    def get_policy(self):\n",
    "        \"\"\"\n",
    "        Choisi la meilleure action par emplacement.\n",
    "        \"\"\"\n",
    "        policy = {}\n",
    "        for x_y in self.q_function.keys():\n",
    "            action_reward       = self.q_function[x_y]\n",
    "            liste_action_reward = [(action, action_reward[action]) for action in action_reward.keys()]\n",
    "            sort_actions = sorted(liste_action_reward, key=lambda tuple_: tuple_[1])\n",
    "            (action, _) = sort_actions[-1]\n",
    "            policy[x_y] = action\n",
    "        return policy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Action ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) on crée les épisodes, et on met à jour la q_function en fonction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5000 / 10000 / 15000 / 20000 / 25000 / 30000 / 35000 / 40000 / 45000 / "
     ]
    }
   ],
   "source": [
    "acteur           = agent()\n",
    "env              = environnement()\n",
    "alpha            = 0.4\n",
    "nb_apprentissage = 50000\n",
    "\n",
    "for Nieme_episode in range(nb_apprentissage):\n",
    "    acteur.reset_position()\n",
    "    \n",
    "    episode     = env.create_episode(acteur)\n",
    "    last_reward = episode[-1][\"reward\"]\n",
    "    \n",
    "    for  i, dico in enumerate(episode):\n",
    "        x      = dico[\"current_x\"]\n",
    "        y      = dico[\"current_y\"]\n",
    "        action = dico[\"action\"   ]\n",
    "        \n",
    "        poids_changement                  = i+1 / len(episode) \n",
    "        changement                        = last_reward  * poids_changement\n",
    "        acteur.q_function[(x,y)][action] += changement\n",
    "\n",
    "    \n",
    "    if Nieme_episode%5000 ==0:\n",
    "        print(Nieme_episode, end=\" / \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question : combien d'épisodes sont créés ? (réponse : nb_apprentssage * max_iter)\n",
    "# Question : créez une fonction de timing de la fonction create_episode => tracer une courbe du temps de calcul estimé en fonctoin de cela (utiliser timit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = acteur.get_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) afficher le résultat de l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for x in range(10):\n",
    "    df[x] = [\"\"]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "panneau = {\n",
    "    \"bas\"    : \"↑\",\n",
    "    \"haut\"   : \"↓\",\n",
    "    \"gauche\" : \"←\",\n",
    "    \"droite\" : \"→\" }\n",
    "panneau2 = {\n",
    "    \"bas\"    : \"↑\",\n",
    "    \"haut\"   : \"↓\",\n",
    "    \"gauche\" : \"←\",\n",
    "    \"droite\" : \"→\" }\n",
    "\n",
    "for x in range(environnement.y_max):\n",
    "    for y in range(environnement.x_max):\n",
    "        action = policy[(x,y)]\n",
    "        \n",
    "        if (x,y) in environnement.but:\n",
    "            df.iloc[x,y] = \"x\"\n",
    "        else:\n",
    "            df.iloc[x,y] = panneau[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>→</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "      <td>↓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>←</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>←</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>x</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↓</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>←</td>\n",
       "      <td>←</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>→</td>\n",
       "      <td>↓</td>\n",
       "      <td>↓</td>\n",
       "      <td>←</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>x</td>\n",
       "      <td>←</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>↑</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>←</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>↑</td>\n",
       "      <td>→</td>\n",
       "      <td>→</td>\n",
       "      <td>↑</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9\n",
       "0  →  ↓  ↓  ↓  ↓  ↓  ↓  ↓  ↓  ↓\n",
       "1  →  →  ↓  ↓  ↓  ↓  ↓  ←  ←  ↓\n",
       "2  →  →  →  ↓  ↓  ↓  ←  ↓  ↓  ←\n",
       "3  →  →  →  →  x  ←  ←  ←  ←  ←\n",
       "4  →  →  →  →  ↑  ↑  ↑  ↓  ←  ←\n",
       "5  →  →  →  ↑  ↑  ↑  ←  ←  ↓  ↓\n",
       "6  →  →  ↑  ↑  ↑  ↑  →  ↓  ↓  ←\n",
       "7  →  →  ↑  →  →  ↑  →  →  x  ←\n",
       "8  ↑  ↑  ↑  →  ↑  →  →  ↑  ↑  ↑\n",
       "9  ↑  →  →  ←  ↑  ↑  ↑  →  →  ↑"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Exercice :\n",
    "\n",
    "    - créez un script qui trace le chemin emprunté par cet agent selon un point de départ donné par l'utilisateur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1) Réponse : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Quel x de départ3\n",
      "Quel y de départ3\n",
      "droite\n",
      "3 4\n",
      "haut\n",
      "arrivé !\n",
      "----------------------------------\n",
      "Quel x de départ3\n",
      "Quel y de départ0\n",
      "droite\n",
      "3 1\n",
      "droite\n",
      "3 2\n",
      "droite\n",
      "3 3\n",
      "droite\n",
      "3 4\n",
      "haut\n",
      "arrivé !\n",
      "----------------------------------\n",
      "Quel x de départ7\n",
      "Quel y de départ3\n",
      "droite\n",
      "7 4\n",
      "droite\n",
      "7 5\n",
      "bas\n",
      "6 5\n",
      "bas\n",
      "5 5\n",
      "bas\n",
      "4 5\n",
      "bas\n",
      "3 5\n",
      "gauche\n",
      "3 4\n",
      "haut\n",
      "arrivé !\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"-\"*34)\n",
    "    x_depart = int(input(\"Quel x de départ\"))\n",
    "    y_depart = int(input(\"Quel y de départ\"))\n",
    "    \n",
    "    for i in range(40):\n",
    "        action = policy[x_depart,y_depart]\n",
    "        print(action)\n",
    "        next_x, next_y, sorti  = env.get_next_position(current_x = x_depart, \n",
    "                                                       current_y = y_depart, \n",
    "                                                       action    = action)\n",
    "        \n",
    "        if env.est_fini(x_depart, y_depart):\n",
    "            print(\"arrivé !\")\n",
    "            break\n",
    "        if sorti:\n",
    "            print(\"perdu !\")\n",
    "            break\n",
    "        print(next_x, next_y)\n",
    "        x_depart, y_depart =    next_x, next_y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
